{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "earlier-investing",
   "metadata": {},
   "source": [
    "## Join the Duet Server the Data Owner 1 connected to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sized-session",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤  🎸  ♪♪♪ Joining Duet ♫♫♫  🎻  🎹\n",
      "\n",
      "♫♫♫ >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "♫♫♫ > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > ❤️ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "♫♫♫ > Punching through firewall to OpenGrid Network Node at:\n",
      "♫♫♫ > http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000\n",
      "♫♫♫ >\n",
      "♫♫♫ > ...waiting for response from OpenGrid Network... \n",
      "♫♫♫ > \u001b[92mDONE!\u001b[0m\n",
      "\n",
      "♫♫♫ > \u001b[92mCONNECTED!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import syft as sy\n",
    "duet1 = sy.join_duet(loopback=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-container",
   "metadata": {},
   "source": [
    "## Join the Duet Server the Data Owner 2 connected to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "centered-knife",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤  🎸  ♪♪♪ Joining Duet ♫♫♫  🎻  🎹\n",
      "\n",
      "♫♫♫ >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "♫♫♫ > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > ❤️ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "♫♫♫ > Punching through firewall to OpenGrid Network Node at:\n",
      "♫♫♫ > http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000\n",
      "♫♫♫ >\n",
      "♫♫♫ > ...waiting for response from OpenGrid Network... \n",
      "♫♫♫ > \u001b[92mDONE!\u001b[0m\n",
      "\n",
      "♫♫♫ > \u001b[92mCONNECTED!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "duet2 = sy.join_duet(loopback=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "duet1.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "duet2.store.pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-cradle",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_ptr = duet1.store[0]\n",
    "data2_ptr = duet2.store[0]\n",
    "\n",
    "print(data1_ptr)\n",
    "print(data2_ptr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-savage",
   "metadata": {},
   "source": [
    "### Create Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-portland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 1\n",
    "out_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-personal",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyNet(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(SyNet, self).__init__(torch_ref=torch_ref)\n",
    "        self.linear = self.torch_ref.nn.Linear(in_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-factor",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(iterations, model, torch_ref, optim, data_ptr, target_ptr):\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "        output = model(data_ptr)\n",
    "\n",
    "        loss = torch_ref.nn.functional.mse_loss(output, target_ptr)\n",
    "\n",
    "        loss_item = loss.item()\n",
    "\n",
    "        loss_value = loss_item.get(\n",
    "            reason=\"To evaluate training progress\",\n",
    "            request_block=True,\n",
    "            timeout_secs=5,\n",
    "        )\n",
    "\n",
    "        print(\"Epoch\", i, \"loss\", loss_value)\n",
    "\n",
    "        losses.append(loss_value)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-guide",
   "metadata": {},
   "source": [
    "#### Send one copy of the model to each data owner or client and train them remotely one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-tumor",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = SyNet(torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-partner",
   "metadata": {},
   "source": [
    "Train on Data Owner 1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-rogers",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model1 = base_model.send(duet1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_torch1 = duet1.torch\n",
    "params = remote_model1.parameters()\n",
    "optim1 = remote_torch1.optim.Adam(params=params, lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-spirit",
   "metadata": {},
   "source": [
    "Dummy target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "target1_ptr = th.FloatTensor(np.array([5, 10, 15, 22, 30, 38]).reshape(-1, 1))\n",
    "target1_ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 10\n",
    "losses = train(iteration, remote_model1, remote_torch1, optim1, data1_ptr, target1_ptr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-election",
   "metadata": {},
   "source": [
    "Train on Data Owner 2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "continental-carter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Sending local model\n",
      "> Creating remote model\n",
      "  Sending local layer: linear\n",
      "\n",
      "> Finished sending local model <\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "remote_model2 = base_model.send(duet2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cellular-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_torch2 = duet2.torch\n",
    "params = remote_model2.parameters()\n",
    "optim2 = remote_torch2.optim.Adam(params=params, lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-material",
   "metadata": {},
   "source": [
    "Dummy Target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "unlikely-digest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[35.],\n",
       "        [40.],\n",
       "        [45.],\n",
       "        [55.],\n",
       "        [60.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target2_ptr = th.FloatTensor(np.array([35, 40, 45, 55, 60]).reshape(-1, 1))\n",
    "target2_ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "loose-aging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 4783.2255859375\n",
      "Epoch 1 loss 3764.81591796875\n",
      "Epoch 2 loss 2872.36083984375\n",
      "Epoch 3 loss 2107.156494140625\n",
      "Epoch 4 loss 1469.0284423828125\n",
      "Epoch 5 loss 955.904296875\n",
      "Epoch 6 loss 563.3424682617188\n",
      "Epoch 7 loss 284.0714416503906\n",
      "Epoch 8 loss 107.63623046875\n",
      "Epoch 9 loss 20.289325714111328\n"
     ]
    }
   ],
   "source": [
    "iteration = 10\n",
    "losses = train(iteration, remote_model2, remote_torch2, optim2, data2_ptr, target2_ptr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-gravity",
   "metadata": {},
   "source": [
    "### Averaging Model Updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-bangladesh",
   "metadata": {},
   "source": [
    "Ideally, there will be a coordinator server with a secure aggreagtor who will get the model updates from different clients and make an aggregation. For the case of simplicity, in this example we will make the Data Sceintist server work as the coordinator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-passage",
   "metadata": {},
   "source": [
    "### Little sanity check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eastern-silicon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model parameters:\n",
      "[Parameter containing:\n",
      "tensor([[-0.2793]], requires_grad=True), Parameter containing:\n",
      "tensor([0.2700], requires_grad=True)]\n",
      "\n",
      "Remote model1 parameters:\n",
      "[Parameter containing:\n",
      "tensor([[0.6305]], requires_grad=True), Parameter containing:\n",
      "tensor([1.1781], requires_grad=True)]\n",
      "\n",
      "Remote model2 parameters:\n",
      "[Parameter containing:\n",
      "tensor([[0.6246]], requires_grad=True), Parameter containing:\n",
      "tensor([1.1733], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "param1 = remote_model1.parameters().get(request_block=True)\n",
    "param2 = remote_model2.parameters().get(request_block=True)\n",
    "\n",
    "print(\"Base Model parameters:\")\n",
    "print(base_model.parameters())\n",
    "print()\n",
    "\n",
    "print(\"Remote model1 parameters:\")\n",
    "print(param1)\n",
    "print()\n",
    "\n",
    "print(\"Remote model2 parameters:\")\n",
    "print(param2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-beijing",
   "metadata": {},
   "source": [
    "As you can see, the remote model paramter values are different from the base model paramter values. That means the remote copies of our base model got trained and updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afraid-bishop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Downloading remote model\n",
      "> Creating local model\n",
      "  Downloading remote layer: linear\n",
      "\n",
      "> Finished downloading remote model <\n",
      "\n",
      "\n",
      "> Saving model weights\n",
      "> Finished saving weights\n",
      "OrderedDict([('linear.weight', tensor([[0.6305]])), ('linear.bias', tensor([1.1781]))])\n"
     ]
    }
   ],
   "source": [
    "remote_model1_updates = remote_model1.get(\n",
    "    request_block=True\n",
    ").state_dict()\n",
    "\n",
    "print(remote_model1_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "limiting-slope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Downloading remote model\n",
      "> Creating local model\n",
      "  Downloading remote layer: linear\n",
      "\n",
      "> Finished downloading remote model <\n",
      "\n",
      "\n",
      "> Saving model weights\n",
      "> Finished saving weights\n",
      "OrderedDict([('linear.weight', tensor([[0.6246]])), ('linear.bias', tensor([1.1733]))])\n"
     ]
    }
   ],
   "source": [
    "remote_model2_updates = remote_model2.get(\n",
    "    request_block=True\n",
    ").state_dict()\n",
    "\n",
    "print(remote_model2_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "personalized-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-platform",
   "metadata": {},
   "source": [
    "Let's do the aggregation of the weights. In this example, we will just calculate the average of corresponding weights from each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "experimental-pulse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear.weight', tensor([[0.6276]])), ('linear.bias', tensor([1.1757]))])\n"
     ]
    }
   ],
   "source": [
    "avg_updates = OrderedDict()\n",
    "avg_updates[\"linear.weight\"] = (\n",
    "    remote_model1_updates[\"linear.weight\"] + remote_model2_updates[\"linear.weight\"]\n",
    ") / 2\n",
    "avg_updates[\"linear.bias\"] = (\n",
    "    remote_model1_updates[\"linear.bias\"] + remote_model2_updates[\"linear.bias\"]\n",
    ") / 2\n",
    "\n",
    "print(avg_updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-scotland",
   "metadata": {},
   "source": [
    "### Load aggregated weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "hungarian-chess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Creating local model\n"
     ]
    }
   ],
   "source": [
    "combined_model = SyNet(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "exempt-gathering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Loading model weights\n",
      "linear state dict loaded with: <All keys matched successfully>\n",
      "> Finished loading weights\n"
     ]
    }
   ],
   "source": [
    "combined_model.load_state_dict(avg_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "beautiful-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "del avg_updates, remote_model1_updates, remote_model2_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "compressed-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = th.FloatTensor(np.array([17, 25, 32, 50, 80]).reshape(-1, 1))\n",
    "test_target = th.FloatTensor(np.array([12, 15, 20, 30, 50]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "assured-amount",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 11.84467887878418 Ground Truth: 12.0\n",
      "Prediction: 16.86537742614746 Ground Truth: 15.0\n",
      "Prediction: 21.25848960876465 Ground Truth: 20.0\n",
      "Prediction: 32.5550651550293 Ground Truth: 30.0\n",
      "Prediction: 51.382686614990234 Ground Truth: 50.0\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_data)):\n",
    "        sample = test_data[i]\n",
    "        y_hat = combined_model(sample)\n",
    "\n",
    "        print(f\"Prediction: {y_hat.item()} Ground Truth: {test_target[i].item()}\")\n",
    "        preds.append(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "charged-dragon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: -4.478724956512451 Ground Truth: 12.0\n",
      "Prediction: -6.713418483734131 Ground Truth: 15.0\n",
      "Prediction: -8.66877555847168 Ground Truth: 20.0\n",
      "Prediction: -13.696836471557617 Ground Truth: 30.0\n",
      "Prediction: -22.076936721801758 Ground Truth: 50.0\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_data)):\n",
    "        sample = test_data[i]\n",
    "        y_hat = base_model(sample)\n",
    "\n",
    "        print(f\"Prediction: {y_hat.item()} Ground Truth: {test_target[i].item()}\")\n",
    "        preds.append(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-textbook",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-diploma",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "documented-italy",
   "metadata": {},
   "source": [
    "## Comparison to classical linear regression on centralised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "in_dim = 1\n",
    "out_dim = 1\n",
    "\n",
    "\n",
    "class ClassicalLR(torch.nn.Module):\n",
    "    def __init__(self, torch):\n",
    "        super(ClassicalLR, self).__init__()\n",
    "        self.linear = torch.nn.Linear(in_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "classical_model = ClassicalLR(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.FloatTensor(\n",
    "    np.array([5, 15, 25, 35, 45, 55, 60, 65, 75, 85, 95]).reshape(-1, 1)\n",
    ")\n",
    "target = torch.FloatTensor(\n",
    "    np.array([5, 10, 15, 22, 30, 38, 35, 40, 45, 55, 60]).reshape(-1, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classic_train(iterations, model, torch, optim, data, target, criterion):\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        loss_item = loss.item()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\"Epoch\", i, \"loss\", loss_item)\n",
    "\n",
    "        losses.append(loss_item)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = classical_model.parameters()\n",
    "optim = torch.optim.Adam(params=params, lr=0.1)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 100\n",
    "losses = classic_train(\n",
    "    iteration, classical_model, torch, optim, data, target, criterion\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-airline",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = th.FloatTensor(np.array([17, 25, 32, 50, 80]).reshape(-1, 1))\n",
    "test_target = th.FloatTensor(np.array([12, 15, 20, 30, 50]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-blood",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_data)):\n",
    "        sample = test_data[i]\n",
    "        y_hat = classical_model(sample)\n",
    "\n",
    "        print(f\"Prediction: {y_hat.item()} Ground Truth: {test_target[i].item()}\")\n",
    "        preds.append(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-makeup",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
